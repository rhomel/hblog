
# Hello Humans

We now live in the age of generative AI. Unfortunately this means the world is
now getting filled with more and more "artificial" content. That's another way
of saying "authentic" human generated content is decreasing.

As a fellow human deeply invested in technology, this is a huge mixture of
emotions: excitement and uncomfortable existentialism.

Let's ignore the p-doom scenarios for now. I'd like to keep this first post
somewhat positive after-all.

"We're at the dawn of the age of abundance" is often the most positive outlook
when it comes to predictions of the future. "If we (humans) get this right, in
the future you can have anything you want." That sounds really great and
promising.

But what if what I want is human interaction?

The counter argument for anything generated by AI is essentially the duck test:

> If it looks like a duck, swims like a duck, and quacks like a duck, then it
> probably is a duck.

Usually it isn't phrased like that. The conversion is often more nuanced,
something like:

```
George: There's an awful lot of AI slop these days, just today I was reviewing
        several AI generated code commits.

Alice:  Ok, but did they work?

George: Yes, but there were so many code quality issues! And does anyone even
        understand what the code is doing?

Alice:  Hmm, does it matter?
```

Here George laments that the craft of writing code is now lost to the means.
And Alice argues bluntly that the craft was not necessarily important.

If you asked me which side I was on, not more than a few weeks ago, I would
have said I'm with George.

These days, especially after being force and actually using the LLMs for
coding, I'm more in the middle: it is undeniable that the LLM will achieve
knowledge and speeds faster than I can ever hope to achieve in my lifetime. So
if my goal is simply to produce output, and the code is an accident, then to
*not* take advantage of the LLM is a waste of my time.

However that still doesn't answer my question: what if what people want is
human interaction? If it looks like a human, walks like a human, and talks like
a human, is it really human?

Most of us would say no, and no matter how impressive AI gets, its species is
something not human.

And that is actually fine. Take pets for example. We don't necessarily look at
our pets and expect them to *be* human. Pet owners would however argue they are
in some ways equal to humans. But no one can deny that a pet does not have the
same DNA as a human.

So now my prediction: humans will and always desire the human touch for a
subset of their needs. It won't be 100% and it won't be 0% either. But
somewhere in the middle. Some will desire more and others less. But the average
will fall bluntly in the middle.

